{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from dreamai_dl.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class UnNormalize(transforms.Normalize):\n",
    "    def __init__(self,mean,std,*args,**kwargs):\n",
    "        mean = [-m/s for m,s in zip(mean,std)]\n",
    "        std = [1/s for s in std]\n",
    "        super().__init__(mean, std, *args, **kwargs)\n",
    "\n",
    "def is_sequential(x):\n",
    "    return isinstance(x, nn.Sequential)\n",
    "\n",
    "def params(m):\n",
    "    return [p for p in m.parameters()]\n",
    "\n",
    "def is_frozen(model):\n",
    "    return np.array([not p.requires_grad for p in (params(model))]).all()\n",
    "\n",
    "def is_unfrozen(model):\n",
    "    return np.array([p.requires_grad for p in (params(model))]).all()\n",
    "\n",
    "def freeze_params(params):\n",
    "    for p in params:\n",
    "        p.requires_grad = False\n",
    "\n",
    "def unfreeze_params(params):\n",
    "    for p in params:\n",
    "        p.requires_grad = True\n",
    "\n",
    "def freeze_model(model):\n",
    "    freeze_params(model.parameters())\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    unfreeze_params(model.parameters())\n",
    "\n",
    "def get_norm(tfms):\n",
    "    if tfms is None:\n",
    "        return tfms\n",
    "    try:\n",
    "        tfms_list = list(tfms)\n",
    "    except:\n",
    "        tfms_list = list(tfms.transforms)\n",
    "    for t in tfms_list:\n",
    "        if is_norm(t):\n",
    "            return t\n",
    "    return None\n",
    "\n",
    "def is_norm(x):\n",
    "    return type(x).__name__ == 'Normalize'\n",
    "\n",
    "def get_norm_id(tfms):\n",
    "    try:\n",
    "        tfms_list = list(tfms)\n",
    "    except:\n",
    "        tfms_list = tfms.transforms\n",
    "    for i,t in enumerate(tfms_list):\n",
    "        if is_norm(t):\n",
    "            return t,i\n",
    "    return None, None\n",
    "\n",
    "def del_norm(tfms, idx=None):\n",
    "    if idx is None:\n",
    "        idx = get_norm_id(tfms)[1]\n",
    "    if idx is not None:\n",
    "        del tfms.transforms[idx]\n",
    "\n",
    "def update_norm(tfms, mean, std, idx=None):\n",
    "    if idx is None:\n",
    "        idx = get_norm_id(tfms)[1]\n",
    "    if idx is not None:\n",
    "        tfms.transforms[idx].mean = mean\n",
    "        tfms.transforms[idx].std = std\n",
    "    else:\n",
    "        tfms.transforms.append(transforms.Normalize(mean=mean, std=std))\n",
    "\n",
    "def is_tensor(x):\n",
    "    return isinstance(x, torch.Tensor)\n",
    "\n",
    "def tensor_to_img(t):\n",
    "    if t.dim() > 3:\n",
    "        return [np.array(np.transpose(t_,(1,2,0))) for t_ in t]\n",
    "    return np.array(np.transpose(t,(1,2,0)))\n",
    "\n",
    "def plt_show(im, cmap=None, title='', figsize=(7,7)):\n",
    "    if path_or_str(im):\n",
    "        im = rgb_read(im)\n",
    "    if is_tensor(im):\n",
    "        im = tensor_to_img(im)\n",
    "        if is_list(im): im = im[0]\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    plt.imshow(im, cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def show_img(img, cmap=None, titles=[''], figsize=(7,7)):\n",
    "    if not is_list(img):\n",
    "        imgs = [img]\n",
    "    else:\n",
    "        imgs = img\n",
    "    [plt_show(img, cmap=cmap, title=title, figsize=figsize) for img,title in zip(imgs,titles)]\n",
    "\n",
    "def plot_loss_and_acc(log_dir, loss_ylim=(0.0, 0.9), acc_ylim=(0.7, 1.0), save_loss=None, save_acc=None):\n",
    "\n",
    "    metrics = pd.read_csv(f\"{log_dir}/metrics.csv\")\n",
    "\n",
    "    aggreg_metrics = []\n",
    "    agg_col = \"epoch\"\n",
    "    for i, dfg in metrics.groupby(agg_col):\n",
    "        agg = dict(dfg.mean())\n",
    "        agg[agg_col] = i\n",
    "        aggreg_metrics.append(agg)\n",
    "\n",
    "    df_metrics = pd.DataFrame(aggreg_metrics)\n",
    "    df_metrics[[\"train_loss\", \"val_loss\"]].plot(\n",
    "        grid=True, legend=True, xlabel=\"Epoch\", ylabel=\"Loss\"\n",
    "    )\n",
    "\n",
    "    plt.ylim(loss_ylim)\n",
    "    if save_loss is not None:\n",
    "        plt.savefig(save_loss)\n",
    "\n",
    "    df_metrics[[\"train_acc\", \"val_acc\"]].plot(\n",
    "        grid=True, legend=True, xlabel=\"Epoch\", ylabel=\"ACC\"\n",
    "    )\n",
    "\n",
    "    plt.ylim(acc_ylim)\n",
    "    if save_acc is not None:\n",
    "        plt.savefig(save_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
